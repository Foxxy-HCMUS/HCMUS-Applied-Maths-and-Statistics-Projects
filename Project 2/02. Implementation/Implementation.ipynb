{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cài đặt thuật toán tiến trước, thuật toán Viterbi, và thuật toán Baum-Welch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Thuật toán tiến trước"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://github.com/adeveloperdiary/HiddenMarkovModel/blob/master/part2/forward.py](https://github.com/adeveloperdiary/HiddenMarkovModel/blob/master/part2/forward.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_algorithm(observation, transition_prob, emission_prob, initial_distribution):\n",
    "    alpha = np.zeros((observation.shape[0], transition_prob.shape[0]))\n",
    "\n",
    "    alpha[0, :] = initial_distribution * emission_prob[:, observation[0]]\n",
    "\n",
    "    for i in range(1, observation.shape[0]):\n",
    "        for j in range(transition_prob.shape[0]):\n",
    "            alpha[i, j] = alpha[i - 1].dot(transition_prob[:, j]) * emission_prob[j, observation[i]]\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Thuật toán Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://github.com/adeveloperdiary/HiddenMarkovModel/blob/master/part4/Viterbi.py](https://github.com/adeveloperdiary/HiddenMarkovModel/blob/master/part4/Viterbi.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_algorithm(observation, transition_prob, emission_prob, initial_distribution):\n",
    "    T = observation.shape[0]\n",
    "    M = transition_prob.shape[0]\n",
    "\n",
    "    omega = np.zeros((T, M))\n",
    "    omega[0, :] = np.log(initial_distribution * emission_prob[:, observation[0]])\n",
    "\n",
    "    prev = np.zeros((T - 1, M))\n",
    "\n",
    "    for i in range(1, T):\n",
    "        for j in range(M):\n",
    "            # the same as forward probability\n",
    "            probability = omega[i - 1] + np.log(transition_prob[:, j]) + np.log(emission_prob[j, observation[i]])\n",
    "\n",
    "            # the most probable state given previous state at time i    (1)\n",
    "            prev[i - 1, j] = np.argmax(probability)\n",
    "\n",
    "            # the probability of the most probable state                (2)\n",
    "            omega[i, j] = np.max(probability)\n",
    "    \n",
    "    # path array\n",
    "    path = np.zeros(T)\n",
    "\n",
    "    # the most probable state at the last time step\n",
    "    last_state = np.argmax(omega[T - 1, :])\n",
    "    path[0] = last_state\n",
    "\n",
    "    backtrack_index = 1\n",
    "\n",
    "    for i in range(T - 2, -1, -1):\n",
    "        path[backtrack_index] = prev[i, int(last_state)]\n",
    "        last_state = prev[i, int(last_state)]\n",
    "        backtrack_index += 1\n",
    "\n",
    "    # flip the path array\n",
    "    path = np.flip(path, axis = 0)\n",
    "\n",
    "    # return path\n",
    "\n",
    "    # convert numeric values to actual hidden states\n",
    "    result = []\n",
    "\n",
    "    for p in path:\n",
    "        if p == 0:\n",
    "            result.append(\"A\")\n",
    "        else:\n",
    "            result.append(\"B\")\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Thuật toán Baum - Welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_algorithm(observation, transition_prob, emission_prob):\n",
    "    beta = np.zeros((observation.shape[0], transition_prob.shape[0]))\n",
    "    beta[observation.shape[0] - 1] = np.ones(transition_prob.shape[0])\n",
    "\n",
    "    # loop backwards from t - 2 to 0\n",
    "    for i in range(observation.shape[0] -2, -1, -1):\n",
    "        for j in range(transition_prob.shape[0]):\n",
    "            beta[i, j] = (beta[i + 1] * emission_prob[:, observation[i + 1]]).dot(transition_prob[j, :])\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch_algorithm(observation, transition_prob, emission_probability, initial_distribution, n_iter=100):\n",
    "    M = transition_prob.shape[0]\n",
    "    T = len(observation)\n",
    "\n",
    "    for n in range(n_iter):\n",
    "        alpha = forward_algorithm(observation, transition_prob, emission_probability, initial_distribution)\n",
    "        beta = backward_algorithm(observation, transition_prob, emission_probability)\n",
    "\n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            denominator = np.dot(np.dot(alpha[t, :].T, transition_prob) * emission_probability[:, observation[t + 1]].T, beta[t + 1, :])\n",
    "            for i in range(M):\n",
    "                numerator = alpha[t, i] * transition_prob[i, :] * emission_probability[:, observation[t + 1]].T * beta[t + 1, :].T\n",
    "                xi[i, :, t] = numerator / denominator\n",
    "\n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        transition_prob = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "\n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    "\n",
    "        K = emission_probability.shape[1]\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for l in range(K):\n",
    "            emission_probability[:, l] = np.sum(gamma[:, observation == l], axis=1)\n",
    "\n",
    "        emission_probability = np.divide(emission_probability, denominator.reshape((-1, 1)))\n",
    "\n",
    "    return (transition_prob, emission_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "obs = data['Visible'].values\n",
    "\n",
    "# transition probabilities\n",
    "trans_prob = np.ones((2, 2))\n",
    "trans_prob = trans_prob / np.sum(trans_prob, axis = 1)\n",
    "\n",
    "# emission probabilities\n",
    "emiss_prob = np.array(((1, 3, 5), (2, 4, 6)))\n",
    "emiss_prob = emiss_prob / np.sum(emiss_prob, axis = 1).reshape((-1, 1))\n",
    "\n",
    "# equal probabilities for the initial distribution\n",
    "init_dist = np.array((0.5, 0.5))\n",
    "\n",
    "trans_prob, emiss_prob = baum_welch_algorithm(obs, trans_prob, emiss_prob, init_dist)\n",
    "\n",
    "result = viterbi_algorithm(obs, trans_prob, emiss_prob, init_dist)\n",
    "\n",
    "f = open(\"result.txt\", \"w\")\n",
    "for row in result:\n",
    "    f.write(row + ' ')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e918aaa81d99c652401bdd1a0c185581595fb477ac919641bd65261b5d7782a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
