{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cài đặt thuật toán tiến trước, thuật toán Viterbi, và thuật toán Baum-Welch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Thuật toán tiến trước"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://github.com/adeveloperdiary/HiddenMarkovModel/blob/master/part2/forward.py](https://github.com/adeveloperdiary/HiddenMarkovModel/blob/master/part2/forward.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_algorithm(observation, transition_prob, emission_prob, initial_distribution, vocabulary):\n",
    "    alpha = np.zeros((observation.shape[0], transition_prob.shape[0]))\n",
    "    \n",
    "    id = np.where(vocabulary == observation[0])\n",
    "\n",
    "    alpha[0, :] = initial_distribution * emission_prob[:, id[0][0]]\n",
    "\n",
    "    for i in range(1, observation.shape[0]):\n",
    "        for j in range(transition_prob.shape[0]):\n",
    "            id = np.where(vocabulary == observation[i])\n",
    "            alpha[i, j] = alpha[i - 1].dot(transition_prob[:, j]) * emission_prob[j, id[0][0]]\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Thuật toán Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://github.com/adeveloperdiary/HiddenMarkovModel/blob/master/part4/Viterbi.py](https://github.com/adeveloperdiary/HiddenMarkovModel/blob/master/part4/Viterbi.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_algorithm(observation, transition_prob, emission_prob, initial_distribution, vocabulary):\n",
    "    T = observation.shape[0] \n",
    "    M = transition_prob.shape[0] \n",
    "\n",
    "    omega = np.zeros((T, M))\n",
    "    id = np.where(vocabulary == observation[0])\n",
    "    \n",
    "    omega[0, :] = np.log(initial_distribution * emission_prob[:, id[0][0]])\n",
    "\n",
    "    prev = np.zeros((T - 1, M))\n",
    "\n",
    "    for i in range(1, T):\n",
    "        for j in range(M):\n",
    "            \n",
    "            # find the index of the observation in the vocabulary\n",
    "            id = np.where(vocabulary == observation[i])\n",
    "\n",
    "            # the same as forward probability\n",
    "            probability = omega[i - 1] + np.log(transition_prob[:, j]) + np.log(emission_prob[j, id[0][0]])\n",
    "\n",
    "            # the most probable state given previous state at time i    (1)\n",
    "            prev[i - 1, j] = np.argmax(probability)\n",
    "\n",
    "            # the probability of the most probable state                (2)\n",
    "            omega[i, j] = np.max(probability)\n",
    "\n",
    "    # path array\n",
    "    path = np.zeros(T)\n",
    "\n",
    "    # the most probable state at the last time step\n",
    "    last_state = np.argmax(omega[T - 1, :])\n",
    "    path[0] = last_state\n",
    "\n",
    "    backtrack_index = 1\n",
    "\n",
    "    for i in range(T - 2, -1, -1):\n",
    "        path[backtrack_index] = prev[i, int(last_state)]\n",
    "        last_state = prev[i, int(last_state)]\n",
    "        backtrack_index += 1\n",
    "\n",
    "    # flip the path array\n",
    "    path = np.flip(path, axis = 0)\n",
    "\n",
    "    # return path\n",
    "\n",
    "    # convert numeric values to actual hidden states\n",
    "    result = []\n",
    "\n",
    "    for p in path:\n",
    "        if p == 0:\n",
    "            result.append(\"A\")\n",
    "        else:\n",
    "            result.append(\"B\")\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Thuật toán Baum - Welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_algorithm(observation, transition_prob, emission_prob, vocabulary):\n",
    "    beta = np.zeros((observation.shape[0], transition_prob.shape[0]))\n",
    "    beta[observation.shape[0] - 1] = np.ones(transition_prob.shape[0])\n",
    "\n",
    "    # loop backwards from t - 2 to 0\n",
    "    for i in range(observation.shape[0] -2, -1, -1):\n",
    "        for j in range(transition_prob.shape[0]):\n",
    "            # find the index of the observation in the vocabulary\n",
    "            id = np.where(vocabulary == observation[i + 1])\n",
    "\n",
    "            beta[i, j] = (beta[i + 1] * emission_prob[:, id[0][0]]).dot(transition_prob[j, :])\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch_algorithm(observation, transition_prob, emission_probability, initial_distribution, vocabulary, n_iter=100):\n",
    "    M = transition_prob.shape[0]\n",
    "    T = len(observation)\n",
    "\n",
    "    for n in range(n_iter):\n",
    "        alpha = forward_algorithm(observation, transition_prob, emission_probability, initial_distribution, vocabulary)\n",
    "        beta = backward_algorithm(observation, transition_prob, emission_probability, vocabulary)\n",
    "\n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            id = np.where(vocabulary == observation[t + 1])\n",
    "\n",
    "            denominator = np.dot(np.dot(alpha[t, :].T, transition_prob) * emission_probability[:, id[0][0]].T, beta[t + 1, :])\n",
    "            for i in range(M):\n",
    "                numerator = alpha[t, i] * transition_prob[i, :] * emission_probability[:, id[0][0]].T * beta[t + 1, :].T\n",
    "                xi[i, :, t] = numerator / denominator\n",
    "\n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        transition_prob = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "\n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    "\n",
    "        K = emission_probability.shape[1]\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for l in range(K):\n",
    "            emission_probability[:, l] = np.sum(gamma[:, observation == l], axis=1)\n",
    "\n",
    "        emission_probability = np.divide(emission_probability, denominator.reshape((-1, 1)))\n",
    "\n",
    "    return (transition_prob, emission_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "obs = data['Visible'].values\n",
    "\n",
    "# transition probabilities\n",
    "trans_prob = np.ones((2, 2))\n",
    "trans_prob = trans_prob / np.sum(trans_prob, axis = 1)\n",
    "\n",
    "# emission probabilities\n",
    "emiss_prob = np.array(((1, 3, 5), (2, 4, 6)))\n",
    "emiss_prob = emiss_prob / np.sum(emiss_prob, axis = 1).reshape((-1, 1))\n",
    "\n",
    "# equal probabilities for the initial distribution\n",
    "init_dist = np.array((0.5, 0.5))\n",
    "\n",
    "trans_prob, emiss_prob = baum_welch_algorithm(obs, trans_prob, emiss_prob, init_dist, np.array((0, 1, 2)))\n",
    "\n",
    "result = viterbi_algorithm(obs, trans_prob, emiss_prob, init_dist, np.array((0, 1, 2)))\n",
    "\n",
    "f = open(\"result.txt\", \"w\")\n",
    "for row in result:\n",
    "    f.write(row + ' ')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bài toán: \n",
    "Khi làm quản trò, anh Huy thường sử dụng 2 viên xúc xác khác nhau. Viên đầu tiên là một viên xúc xắc cân bằng, mọi mặt đều có cùng xác suất. Viên thứ hai là một viên xúc xắc lỗi, khi tung sẽ có 50% xác suất ra mặt số 6 và 10% xác suất ra mỗi mặt còn lại. Mỗi lần tung, anh sẽ chọn 1 trong 2 viên xúc xắc này để tung. Người chơi không thể biết anh đã tung viên nào, chỉ biết được lần tung đó ra mặt nào. Ngoài ra, nếu ở lần tung này, anh Huy sử dụng viên xúc xắc cân bằng, thì có 80% khả năng anh sẽ tiếp tục sử dụng viên xúc xắc này cho lần tung tiếp theo (20% còn lại anh sẽ đổi sang dùng viên lỗi). Con số này là 30% đối với viên lỗi (70% đổi sang dùng viên cân bằng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Mô hình hóa tình huống trên bằng một mô hình Markov ẩn. Cho biết các tham số của mô hình này.\n",
    "Mô hình Markov ẩn được xây dựng:\n",
    "- Tập trạng thái Q = {q0: cân bằng, q1: lỗi}.\n",
    "- Ma trận chuyển trạng thái A = [[0.8, 0.2], [0.7, 0.3]] (theo thứ tự a00, a01, a10, a11).\n",
    "- Tập quan sát O gồm các trạng thái được lấy từ tập V = {1, 2, 3, 4, 5, 6}.\n",
    "- Ma trận B (các giá trị observation likelihoods): \n",
    "[[P(1|q0) = 1/6, P(2|q0) = 1/6, P(3|q0) = 1/6, P(4|q0) = 1/6, P(5|q0) = 1/6, P(6|q0) = 1/6],\n",
    " [P(1|q1) = 0.1, P(2|q1) = 0.1, P(3|q1) = 0.1, P(4|q1) = 0.1, P(5|q1) = 0.1, P(6|q1) = 0.5]]\n",
    "- Phân phối ban đầu Pi = [0.5, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Sinh ngẫu nhiên một chuỗi T = 100 lần tung theo đúng mô tả trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[6 6 5 3 2 5 4 2 6 6 2 2 2 6 1 4 5 3 4 1 5 3 6 6 3 3 4 2 4 1 6 6 1 6 5 2 1\n",
      " 2 1 2 6 3 4 6 3 3 1 2 6 6 6 1 6 3 2 6 2 6 1 3 1 6 6 6 6 3 2 2 1 6 4 1 6 2\n",
      " 5 6 5 5 6 4 3 6 6 1 4 1 6 3 4 3 6 5 2 6 6 1 1 6 1 6]\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "'A is the transition probability matrix'\n",
    "A = [[0.8, 0.2], [0.7, 0.3]]\n",
    "\n",
    "'B is the observation likelihoods matrix'\n",
    "B = [[1/6, 1/6, 1/6, 1/6, 1/6, 1/6],[.1, .1, .1, .1, .1, .5]]\n",
    "\n",
    "'D is the number on the faces of the dice'\n",
    "D = [1,2,3,4,5,6]\n",
    "\n",
    "'initial distribution'\n",
    "Pi = np.array((0.5, 0.5))\n",
    "\n",
    "def generate(T: int):\n",
    "    dice = rd.choice([0,1])     # choose a random dice with equal probability 0.5\n",
    "    res = list()\n",
    "    dices = list()\n",
    "    for i in range(0, T):\n",
    "        dices.append(dice)\n",
    "        temp1 = rd.choices(D, B[dice])\n",
    "        res.append(temp1[0])\n",
    "        temp2 = rd.choices([0,1], A[dice])\n",
    "        dice = temp2[0]\n",
    "    print(dices)\n",
    "    return res\n",
    "\n",
    "'Generate a sequence of T = 100 observations'\n",
    "gen = np.array(generate(100))\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Sử dụng thuật toán Viterbi để dự đoán viên xúc xắc được dùng cho mỗi lần tung. Độ chính xác của dự đoán này là bao nhiêu? Hãy lặp lại thí nghiệm này nhiều lần nếu cần thiết. Báo cáo và nhận xét kết quả thu được."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n"
     ]
    }
   ],
   "source": [
    "res1 = viterbi_algorithm(gen, np.array(A), np.array(B), Pi, np.array(D))\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Giả sử bạn là một người chơi, hãy sử dụng thuật toán Baum-Welch để ước lượng các tham số cho mô hình Markov ẩn. Hãy lặp lại thí nghiệm nhiều lần nếu cần thiết. Báo cáo và nhận xét kết quả thu được."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_16544/2692237171.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  xi[i, :, t] = numerator / denominator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan]\n",
      " [nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "# transition probabilities\n",
    "A1 = np.ones((2, 2))\n",
    "A1 = A1 / np.sum(A1, axis = 1)\n",
    "\n",
    "# emission probabilities\n",
    "B1 = np.array(((1, 3, 5, 7, 9, 11), (2, 4, 6, 8, 10, 12)))\n",
    "B1 = B1 / np.sum(B1, axis = 1).reshape((-1, 1))\n",
    "\n",
    "A1, B1 = baum_welch_algorithm(gen, A1, B1, Pi, np.array(D))\n",
    "print(A1)\n",
    "print(B1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
