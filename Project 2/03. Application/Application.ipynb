{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Vận dụng\n",
    "Ứng dụng của mô hình Markov ẩn được lựa chọn: _**`POS tagging`**_ (gán nhãn ngữ pháp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Mô tả bài toán\n",
    "- Đầu vào: Mảng các từ trong một câu theo thứ tự\n",
    "\n",
    "    Ví dụ: `input = [\"the\", \"Dutch\", \"publishing\", \"group\"]`\n",
    "- Đầu ra kỳ vọng: mảng các từ cùng với nhãn đã được gán (sau khi tính toán). Một số từ tiếng anh có nhiều dạng (ví dụ theo từ điển, một từ vừa là *danh từ*, vừa là *động từ* ...) cần phải xác định vai trò của từ trong câu để có thể xác định chính xác nghĩa của từ đó.\n",
    "\n",
    "    Ví dụ: \n",
    "    ```python\n",
    "    output = [\n",
    "        (\"the\", \"DT\"),\n",
    "        (\"Dutch\", \"NNP\"),\n",
    "        (\"publishing\", \"VBG\"),\n",
    "        (\"group\", \"NN\"),\n",
    "    ]\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Tập dữ liệu & Các bước tiền xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Tập dữ liệu\n",
    "Tập dữ liệu: Trích xuất từ [Penn TreeBank](https://www.kaggle.com/datasets/nltkdata/penn-tree-bank) (~5%)\n",
    "\n",
    "Các nhãn gán được sử dụng (Penn TreeBank):\n",
    "\n",
    "Nguồn: [Speech and Language Processing. Daniel Jurafsky & James H. Martin.](https://web.stanford.edu/~jurafsky/slp3/8.pdf)\n",
    "\n",
    "|Nhãn|Ý nghĩa|Ví dụ|\n",
    "|---|---|---|\n",
    "|CC| Liên từ kết hợp | and, but, or |\n",
    "|CD| Số đếm | one, two |\n",
    "|DT| Định từ | a, the |\n",
    "|EX| Tồn tại _there_ | there |\n",
    "|FW| Từ mượn | mea culpa |\n",
    "|IN| Giới từ | of, in, by |\n",
    "|JJ| Tính từ | yellow |\n",
    "|JJR| Tính từ so sánh hơn | bigger |\n",
    "|JJS| Tính từ so sánh nhất | wildest |\n",
    "|LS| Đánh dấu danh sách | 1, 2, One |\n",
    "|MD| Động từ khiếm khuyết | can, should |\n",
    "|NN| Danh từ số ít | llama |\n",
    "|NNS| Danh từ số nhiều | llamas|\n",
    "|NNP| Danh từ riêng số ít | IBM |\n",
    "|NNPS| Danh từ riêng số nhiều | Carolinas |\n",
    "|PDT| Từ chỉ định | all, both |\n",
    "|POS| Kết thúc sở hữu cách | 's |\n",
    "|PRP| Đại từ nhân xưng | I, you, he |\n",
    "|PRP$| Đại từ sở hữu | your, one's |\n",
    "|RB| Trạng từ | quickly |\n",
    "|RBR| Trạng từ so sánh hơn | faster |\n",
    "|RBS| Trạng từ so sánh nhất | fastest |\n",
    "|RP| Tiểu từ | up, off |\n",
    "|SYM| Ký hiệu | +, %, & |\n",
    "|TO| Từ _to_ | to |\n",
    "|UH| Thán từ | ah, oops |\n",
    "|VB| Động từ nguyên mẫu | eat |\n",
    "|VBD| Động từ quá khứ | ate |\n",
    "|VBG| Danh động từ | eating |\n",
    "|VBN| Động từ quá khứ phân từ | eaten |\n",
    "|VBP| Động từ ngôi thứ 3 số ít | eat |\n",
    "|VBZ| Động từ ngôi thứ 3 số nhiều | eats |\n",
    "|WDT| Wh- xác định | which, that |\n",
    "|WP| Wh- đại từ | what, who |\n",
    "|WP$| Wh- sỡ hữu | whose |\n",
    "|WRB| Wh- trạng từ | how, where|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Tiền xử lí\n",
    "\n",
    "Sử dụng thư viện nltk để đọc dataset,\n",
    "\n",
    "Sau khi tải về từ Kaggle,\n",
    "\n",
    "Dataset ban đầu lưu ở `archive/treebank/treebank/combined`, \n",
    "\n",
    "Chia thành 2 phần test và train:\n",
    "- Train: `wsj_0001.mrg` tới `wsj_0190.mrg`\n",
    "- Test: `wsj_0191.mrg` tới `wsj_0199.mrg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |-dataset\n",
      " | |-README\n",
      " | |-test\n",
      " | | |-wsj_0191.mrg\n",
      " | | |-wsj_0192.mrg\n",
      " | | |-wsj_0193.mrg\n",
      " | | |-wsj_0194.mrg\n",
      " | | |-wsj_0195.mrg\n",
      " | | |-wsj_0196.mrg\n",
      " | | |-wsj_0197.mrg\n",
      " | | |-wsj_0198.mrg\n",
      " | | |-wsj_0199.mrg\n",
      " | |-train\n",
      " | | |-wsj_0001.mrg\n",
      " | | |-wsj_0002.mrg\n",
      " | | |-wsj_0003.mrg\n",
      " | | |-wsj_0004.mrg\n",
      " | | |-wsj_0005.mrg\n",
      " | | |-wsj_0006.mrg\n",
      " | | |-wsj_0007.mrg\n",
      " | | |-wsj_0008.mrg\n",
      " | | |-wsj_0009.mrg\n",
      " | | |-wsj_0010.mrg\n",
      " | | |-wsj_0011.mrg\n",
      " | | |-wsj_0012.mrg\n",
      " | | |-wsj_0013.mrg\n",
      " | | |-wsj_0014.mrg\n",
      " | | |-wsj_0015.mrg\n",
      " | | |-wsj_0016.mrg\n",
      " | | |-wsj_0017.mrg\n",
      " | | |-wsj_0018.mrg\n",
      " | | |-wsj_0019.mrg\n",
      " | | |-wsj_0020.mrg\n",
      " | | |-wsj_0021.mrg\n",
      " | | |-wsj_0022.mrg\n",
      " | | |-wsj_0023.mrg\n",
      " | | |-wsj_0024.mrg\n",
      " | | |-wsj_0025.mrg\n",
      " | | |-wsj_0026.mrg\n",
      " | | |-wsj_0027.mrg\n",
      " | | |-wsj_0028.mrg\n",
      " | | |-wsj_0029.mrg\n",
      " | | |-wsj_0030.mrg\n",
      " | | |-wsj_0031.mrg\n",
      " | | |-wsj_0032.mrg\n",
      " | | |-wsj_0033.mrg\n",
      " | | |-wsj_0034.mrg\n",
      " | | |-wsj_0035.mrg\n",
      " | | |-wsj_0036.mrg\n",
      " | | |-wsj_0037.mrg\n",
      " | | |-wsj_0038.mrg\n",
      " | | |-wsj_0039.mrg\n",
      " | | |-wsj_0040.mrg\n",
      " | | |-wsj_0041.mrg\n",
      " | | |-wsj_0042.mrg\n",
      " | | |-wsj_0043.mrg\n",
      " | | |-wsj_0044.mrg\n",
      " | | |-wsj_0045.mrg\n",
      " | | |-wsj_0046.mrg\n",
      " | | |-wsj_0047.mrg\n",
      " | | |-wsj_0048.mrg\n",
      " | | |-wsj_0049.mrg\n",
      " | | |-wsj_0050.mrg\n",
      " | | |-wsj_0051.mrg\n",
      " | | |-wsj_0052.mrg\n",
      " | | |-wsj_0053.mrg\n",
      " | | |-wsj_0054.mrg\n",
      " | | |-wsj_0055.mrg\n",
      " | | |-wsj_0056.mrg\n",
      " | | |-wsj_0057.mrg\n",
      " | | |-wsj_0058.mrg\n",
      " | | |-wsj_0059.mrg\n",
      " | | |-wsj_0060.mrg\n",
      " | | |-wsj_0061.mrg\n",
      " | | |-wsj_0062.mrg\n",
      " | | |-wsj_0063.mrg\n",
      " | | |-wsj_0064.mrg\n",
      " | | |-wsj_0065.mrg\n",
      " | | |-wsj_0066.mrg\n",
      " | | |-wsj_0067.mrg\n",
      " | | |-wsj_0068.mrg\n",
      " | | |-wsj_0069.mrg\n",
      " | | |-wsj_0070.mrg\n",
      " | | |-wsj_0071.mrg\n",
      " | | |-wsj_0072.mrg\n",
      " | | |-wsj_0073.mrg\n",
      " | | |-wsj_0074.mrg\n",
      " | | |-wsj_0075.mrg\n",
      " | | |-wsj_0076.mrg\n",
      " | | |-wsj_0077.mrg\n",
      " | | |-wsj_0078.mrg\n",
      " | | |-wsj_0079.mrg\n",
      " | | |-wsj_0080.mrg\n",
      " | | |-wsj_0081.mrg\n",
      " | | |-wsj_0082.mrg\n",
      " | | |-wsj_0083.mrg\n",
      " | | |-wsj_0084.mrg\n",
      " | | |-wsj_0085.mrg\n",
      " | | |-wsj_0086.mrg\n",
      " | | |-wsj_0087.mrg\n",
      " | | |-wsj_0088.mrg\n",
      " | | |-wsj_0089.mrg\n",
      " | | |-wsj_0090.mrg\n",
      " | | |-wsj_0091.mrg\n",
      " | | |-wsj_0092.mrg\n",
      " | | |-wsj_0093.mrg\n",
      " | | |-wsj_0094.mrg\n",
      " | | |-wsj_0095.mrg\n",
      " | | |-wsj_0096.mrg\n",
      " | | |-wsj_0097.mrg\n",
      " | | |-wsj_0098.mrg\n",
      " | | |-wsj_0099.mrg\n",
      " | | |-wsj_0100.mrg\n",
      " | | |-wsj_0101.mrg\n",
      " | | |-wsj_0102.mrg\n",
      " | | |-wsj_0103.mrg\n",
      " | | |-wsj_0104.mrg\n",
      " | | |-wsj_0105.mrg\n",
      " | | |-wsj_0106.mrg\n",
      " | | |-wsj_0107.mrg\n",
      " | | |-wsj_0108.mrg\n",
      " | | |-wsj_0109.mrg\n",
      " | | |-wsj_0110.mrg\n",
      " | | |-wsj_0111.mrg\n",
      " | | |-wsj_0112.mrg\n",
      " | | |-wsj_0113.mrg\n",
      " | | |-wsj_0114.mrg\n",
      " | | |-wsj_0115.mrg\n",
      " | | |-wsj_0116.mrg\n",
      " | | |-wsj_0117.mrg\n",
      " | | |-wsj_0118.mrg\n",
      " | | |-wsj_0119.mrg\n",
      " | | |-wsj_0120.mrg\n",
      " | | |-wsj_0121.mrg\n",
      " | | |-wsj_0122.mrg\n",
      " | | |-wsj_0123.mrg\n",
      " | | |-wsj_0124.mrg\n",
      " | | |-wsj_0125.mrg\n",
      " | | |-wsj_0126.mrg\n",
      " | | |-wsj_0127.mrg\n",
      " | | |-wsj_0128.mrg\n",
      " | | |-wsj_0129.mrg\n",
      " | | |-wsj_0130.mrg\n",
      " | | |-wsj_0131.mrg\n",
      " | | |-wsj_0132.mrg\n",
      " | | |-wsj_0133.mrg\n",
      " | | |-wsj_0134.mrg\n",
      " | | |-wsj_0135.mrg\n",
      " | | |-wsj_0136.mrg\n",
      " | | |-wsj_0137.mrg\n",
      " | | |-wsj_0138.mrg\n",
      " | | |-wsj_0139.mrg\n",
      " | | |-wsj_0140.mrg\n",
      " | | |-wsj_0141.mrg\n",
      " | | |-wsj_0142.mrg\n",
      " | | |-wsj_0143.mrg\n",
      " | | |-wsj_0144.mrg\n",
      " | | |-wsj_0145.mrg\n",
      " | | |-wsj_0146.mrg\n",
      " | | |-wsj_0147.mrg\n",
      " | | |-wsj_0148.mrg\n",
      " | | |-wsj_0149.mrg\n",
      " | | |-wsj_0150.mrg\n",
      " | | |-wsj_0151.mrg\n",
      " | | |-wsj_0152.mrg\n",
      " | | |-wsj_0153.mrg\n",
      " | | |-wsj_0154.mrg\n",
      " | | |-wsj_0155.mrg\n",
      " | | |-wsj_0156.mrg\n",
      " | | |-wsj_0157.mrg\n",
      " | | |-wsj_0158.mrg\n",
      " | | |-wsj_0159.mrg\n",
      " | | |-wsj_0160.mrg\n",
      " | | |-wsj_0161.mrg\n",
      " | | |-wsj_0162.mrg\n",
      " | | |-wsj_0163.mrg\n",
      " | | |-wsj_0164.mrg\n",
      " | | |-wsj_0165.mrg\n",
      " | | |-wsj_0166.mrg\n",
      " | | |-wsj_0167.mrg\n",
      " | | |-wsj_0168.mrg\n",
      " | | |-wsj_0169.mrg\n",
      " | | |-wsj_0170.mrg\n",
      " | | |-wsj_0171.mrg\n",
      " | | |-wsj_0172.mrg\n",
      " | | |-wsj_0173.mrg\n",
      " | | |-wsj_0174.mrg\n",
      " | | |-wsj_0175.mrg\n",
      " | | |-wsj_0176.mrg\n",
      " | | |-wsj_0177.mrg\n",
      " | | |-wsj_0178.mrg\n",
      " | | |-wsj_0179.mrg\n",
      " | | |-wsj_0180.mrg\n",
      " | | |-wsj_0181.mrg\n",
      " | | |-wsj_0182.mrg\n",
      " | | |-wsj_0183.mrg\n",
      " | | |-wsj_0184.mrg\n",
      " | | |-wsj_0185.mrg\n",
      " | | |-wsj_0186.mrg\n",
      " | | |-wsj_0187.mrg\n",
      " | | |-wsj_0188.mrg\n",
      " | | |-wsj_0189.mrg\n",
      " | | |-wsj_0190.mrg\n"
     ]
    }
   ],
   "source": [
    "!find ./dataset | sed -e \"s/[^-][^\\/]*\\// |/g\" -e \"s/|\\([^ ]\\)/|-\\1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus.reader import BracketParseCorpusReader\n",
    "import glob\n",
    "import string\n",
    "\n",
    "NEAR_ZERO = 0.00000001\n",
    "dataset_path = './dataset'\n",
    "\n",
    "list_of_file_train = glob.glob(dataset_path + '/train/' + '/*.mrg') # Lấy đường dẫn toàn bộ file trong thư mục\n",
    "reader_corpus = BracketParseCorpusReader('.', list_of_file_train)\n",
    "list_of_tagged_sents_train = reader_corpus.tagged_sents() \n",
    "\n",
    "list_of_file_test = glob.glob(dataset_path + '/test/' + '/*.mrg') # Lấy đường dẫn toàn bộ file trong thư mục\n",
    "reader_corpus = BracketParseCorpusReader('.', list_of_file_test)\n",
    "list_of_tagged_sents_test = reader_corpus.tagged_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo `treebank/treebank/combined/README`, dữ liệu ban đầu đã được chạy qua PARTS (Ken Church's stochastic part-of-speech tagger), sau đó được sửa lại thông qua người gán nhãn, ghép với câu dữ liệu gốc tạo thành file Bracket. Một số điểm cần phải sửa đổi sau khi load dataset (Các file `.mrg`):\n",
    "- Các kí hiệu có nhãn dán riêng biệt, để đơn giản cho việc xử lí và thống nhất với các nhãn dán đã liệt kê ở trên, thay đổi nhãn của ký hiệu thành `SYM`\n",
    "- Một số từ không có nhãn, trong dataset được gán là `-NONE-`, cần lọc ra những từ này trước khi xử lí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(list_of_tagged_sents):\n",
    "    # Lọc bỏ những từ không có tag (-NONE-)\n",
    "    list_of_tagged_sents = list(map(\n",
    "        lambda sent: list(filter(\n",
    "            lambda word: word[1] != '-NONE-',\n",
    "            sent\n",
    "        )),\n",
    "        list_of_tagged_sents\n",
    "    ))\n",
    "\n",
    "    # Chuyển đổi tag dấu câu thành SYM\n",
    "    list_of_tagged_sents = list(map(\n",
    "        lambda sent: list(map(\n",
    "            lambda word: (word[0], \"SYM\") if word[1][0] in string.punctuation else word,\n",
    "            sent\n",
    "        )),\n",
    "        list_of_tagged_sents\n",
    "    ))\n",
    "\n",
    "    return list_of_tagged_sents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Du lieu ban dau:\n",
      "[('First', 'NNP'), ('Chicago', 'NNP'), ('Corp.', 'NNP'), ('said', 'VBD'), ('0', '-NONE-'), ('it', 'PRP'), ('completed', 'VBD'), ('its', 'PRP$'), ('$', '$'), ('55.1', 'CD'), ('million', 'CD'), ('*U*', '-NONE-'), ('cash-and-stock', 'JJ'), ('acquisition', 'NN'), ('of', 'IN'), ('closely', 'RB'), ('held', 'VBN'), ('Ravenswood', 'NNP'), ('Financial', 'NNP'), ('Corp.', 'NNP'), (',', ','), ('another', 'DT'), ('Chicago', 'NNP'), ('bank', 'NN'), ('holding', 'VBG'), ('company', 'NN'), ('.', '.')]\n",
      "Du lieu sau khi xu ly:\n",
      "[('First', 'NNP'), ('Chicago', 'NNP'), ('Corp.', 'NNP'), ('said', 'VBD'), ('it', 'PRP'), ('completed', 'VBD'), ('its', 'PRP$'), ('$', 'SYM'), ('55.1', 'CD'), ('million', 'CD'), ('cash-and-stock', 'JJ'), ('acquisition', 'NN'), ('of', 'IN'), ('closely', 'RB'), ('held', 'VBN'), ('Ravenswood', 'NNP'), ('Financial', 'NNP'), ('Corp.', 'NNP'), (',', 'SYM'), ('another', 'DT'), ('Chicago', 'NNP'), ('bank', 'NN'), ('holding', 'VBG'), ('company', 'NN'), ('.', 'SYM')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Du lieu ban dau:\")\n",
    "print(list_of_tagged_sents_test[0])\n",
    "\n",
    "list_of_tagged_sents_test = convert(list_of_tagged_sents_test)\n",
    "list_of_tagged_sents_train = convert(list_of_tagged_sents_train)\n",
    "\n",
    "print(\"Du lieu sau khi xu ly:\")\n",
    "print(list_of_tagged_sents_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Mô tả các thành phần của mô hình\n",
    "- Tập các trạng thái ẩn: là tập các tag có thể của mỗi từ (dựa trên quy tắc gán nhãn của Penn TreeBank dataset).\n",
    "\n",
    "> S = {'JJS', 'PRP$', 'WDT', 'NNP', 'TO', 'PDT', 'WRB', 'WP', 'NNS', 'VB', 'MD', 'RP',  'PRP', 'JJR', 'JJ', 'VBZ', 'RBS', 'VBG', 'POS', 'VBD', 'NN', 'UH', 'FW', 'NNPS', 'WP$', 'EX', 'SYM', 'RBR', 'VBN', 'LS', 'IN', 'DT', 'VBP', 'CD', 'RB', 'CC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagset (36 loại)\n",
    "tag_set = [\n",
    "    'JJS', 'PRP$', 'WDT', 'NNP', 'TO', 'PDT', 'WRB', 'WP', 'NNS', 'VB', 'MD', 'RP', \n",
    "    'PRP', 'JJR', 'JJ', 'VBZ', 'RBS', 'VBG', 'POS', 'VBD', 'NN', 'UH', 'FW', 'NNPS', \n",
    "    'WP$', 'EX', 'SYM', 'RBR', 'VBN', 'LS', 'IN', 'DT', 'VBP', 'CD', 'RB', 'CC'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Các quan sát có thể: Những từ trong câu theo thứ tự đã được gán nhãn, ví dụ `\"I_PRP\", \"am_VBZ\", \"good_JJ\",...`\n",
    "- Các giả thiết của mô hình Markov ẩn phù hợp với tình huống này, do nhãn dán của một từ thường phụ thuộc vào từ phía trước nó (Vd sau động từ khiếm khuyết thường sẽ đi với một động từ nguyên mẫu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các giả thiết được sử dụng\n",
    "#### 1. Giả thiết của Markov ẩn:\n",
    "- Xác suất của một trạng thái cụ thể chỉ phụ thuộc vào trạng thái ngay trước đó (Markov Assumptions)\n",
    "$$P\\left({\\left. {{q_i}} \\right|{q_1} \\ldots {q_{i - 1}}} \\right) = P\\left( {\\left. {{q_i}} \\right|{q_{i - 1}}} \\right)$$\n",
    "- Xác suất của quan sát đầu ra $o_i$ chỉ phụ thuộc vào trạng thái tạo ra quan sát $q_i$, không bị ảnh hưởng bởi các quan sát và trạng thái khác (Independence Assumption).\n",
    "$$P\\left({\\left. {{o_i}} \\right|{q_1} \\ldots {q_{T}}, {o_1} \\ldots {o_{T}}} \\right) = P\\left( {\\left. {{o_i}} \\right|{q_{i}}} \\right)$$\n",
    "#### 2. Giả thiết cho POS tagging\n",
    "- Giả thiết bigram: xác suất của một nhãn chỉ phụ thuộc vào từ phía trước nó, thay vì phụ thuộc vào dãy các nhãn.\n",
    "$$P\\left({{t_1} \\ldots {t_{n}}} \\right) = \\prod_{i=1}^{n}P\\left( {\\left. {{t_i}} \\right|t_0,\\ldots ,{t_{i - 1}}} \\right)  \\approx \\prod_{i=1}^{n}P\\left( {\\left. {{t_i}} \\right|{t_{i - 1}}} \\right)$$\n",
    "- Xác xuất một từ xuất hiện dựa trên nhãn độc lập với những từ  và nhãn xung quanh \n",
    "$$P\\left({{w_1} \\ldots {w_{n}}} | {{t_1} \\ldots {t_{n}}} \\right) \\approx \\prod_{i=1}^{n}P\\left( {\\left. {{w_i}} \\right|{t_{i}}} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mục tiêu của bài toán\n",
    "- Với danh sách từ cho trước $w_1, \\ldots, w_n$, ta cần tìm một danh sách nhãn dán $t_1, \\ldots, t_n$ phù hợp.\n",
    "- Nói cách khác, ta cần tìm:\n",
    "$$\\hat{t}_{1:n}=\\argmax_{t_1\\ldots t_n}{P\\left({{t_1} \\ldots {t_{n}}} | {{w_1} \\ldots {w_{n}}} \\right)}$$\n",
    "Sử dụng định lý Bayes:\n",
    "$$\\hat{t}_{1:n}=\\argmax_{t_1\\ldots t_n}{\\frac{P\\left({{w_1} \\ldots {w_{n}}} | {{t_1} \\ldots {t_{n}}} \\right)P\\left(t_1\\ldots t_n\\right)}{P\\left(w_1\\ldots w_n\\right)}}$$\n",
    "Bỏ qua mẫu số, và áp dụng các giả thuyết đã có, ta được:\n",
    "$$\\hat{t}_{1:n}=\\argmax_{t_1\\ldots t_n}{\\prod_{i=1}^{n}P\\left( {\\left. {{w_i}} \\right|{t_{i}}} \\right)P\\left( {\\left. {{t_i}} \\right|{t_{i - 1}}} \\right)}$$\n",
    "Gọi A là ma trận xác suất chuyển từ nhãn này sang nhãn khác, ta tính toán ước lượng hợp lý cực đại (MLE) của xác suất này bằng cách đếm số lượng nhãn thứ 2 theo sau nhãn thứ nhất trên số lượng nhãn thứ nhất:\n",
    "$$A[t_{i-1}, t_i] = P\\left(t_i|t_{i-1}\\right) = \\frac{C\\left(t_{i-1}, t_i\\right)}{C\\left(t_{i-1}\\right)}$$\n",
    "Gọi B là ma trận xác suất phụ thuộc trạng thái, MLE của xác suất này sẽ là số lần nhãn $t$ được gán cho từ $w$ trên số lượng nhãn $t$:\n",
    "$$B[t_{i}, w_i] = P\\left(w_i|t_{i}\\right) = \\frac{C\\left(t_{i}, w_i\\right)}{C\\left(t_{i}\\right)}$$\n",
    "Gọi $\\pi$ là vector mở đầu phân phối xác suất, được tính bằng số lượng nhãn $t$ mở đầu câu trên tổng số câu:\n",
    "$$\\pi_{t_i} = \\frac{C'(t_i)}{C(sentence)}$$\n",
    "Việc tạo ra được dãy $t_1,\\ldots,t_n$ phù hợp với dãy quan sát $o_1,\\ldots,o_n$ thông qua việc giải mã, ở đây ta sẽ sử dụng [thuật toán Viterbi](https://en.wikipedia.org/wiki/Viterbi_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vd bigram: [1,2,3,4] -> [(1,2), (2,3), (3,4)]\n",
    "# C(t_{i-1}, t_i)\n",
    "def bigramCount(tag_sent_list):\n",
    "    # Tạo bigram trên tag\n",
    "    # Bigram được tạo riêng trên mỗi câu!\n",
    "\n",
    "    bigram = [\n",
    "        (sent[i][1], sent[i + 1][1]) for sent in tag_sent_list for i in range(len(sent) - 1)\n",
    "    ]\n",
    "\n",
    "    map_count = defaultdict(lambda: NEAR_ZERO)\n",
    "    for x in bigram:\n",
    "        if x in map_count:\n",
    "            map_count[x] += 1\n",
    "        else:\n",
    "            map_count[x] = 1\n",
    "    return map_count\n",
    "\n",
    "# Tương tự với unigram\n",
    "# C(t_i)\n",
    "def unigramCount(tag_sent_list):\n",
    "    unigram = [\n",
    "        word[1] for sent in tag_sent_list for word in sent\n",
    "    ]\n",
    "    map_count = defaultdict(lambda: NEAR_ZERO)\n",
    "    for x in unigram:\n",
    "        if x in map_count:\n",
    "            map_count[x] += 1\n",
    "        else:\n",
    "            map_count[x] = 1\n",
    "    return map_count\n",
    "\n",
    "# C(t_i, w_i)\n",
    "def wordtagCount(tag_sent_list):\n",
    "    map_count = defaultdict(lambda: NEAR_ZERO)\n",
    "    for sent in tag_sent_list:\n",
    "        for word in sent:\n",
    "            if word in map_count:\n",
    "                map_count[word] += 1\n",
    "            else:\n",
    "                map_count[word] = 1\n",
    "    return map_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính P(t_{i} | t_{i - 1})\n",
    "def Ptt(bi_cnt, uni_cnt, tag1, tag2):\n",
    "    return bi_cnt[(tag1, tag2)] / uni_cnt[tag1]\n",
    "\n",
    "# Tính P(w_i | t_i)\n",
    "def Pwt(wt_cnt, uni_cnt, tag, word):\n",
    "    count1 = wt_cnt[(word, tag)]\n",
    "    count2 = uni_cnt[tag]\n",
    "    return count1 / count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(tag_set, bi_cnt, uni_cnt):\n",
    "    A = {}\n",
    "    for tag1 in tag_set:\n",
    "        for tag2 in tag_set:\n",
    "            A[(tag1, tag2)] = Ptt(bi_cnt, uni_cnt, tag1, tag2)\n",
    "    return A\n",
    "\n",
    "def emission_matrix(tag_sent_list, tag_set, uni_cnt, wt_cnt):\n",
    "    word_set = []\n",
    "    for sent in tag_sent_list:\n",
    "        for word in sent:\n",
    "            word_set.append(word[0])\n",
    "    word_set = list(set(word_set)) # Loại bỏ từ trùng\n",
    "\n",
    "    B = defaultdict(lambda: NEAR_ZERO)\n",
    "    for tag in tag_set:\n",
    "        for word in word_set:\n",
    "            B[(word, tag)] = Pwt(wt_cnt, uni_cnt, tag, word)\n",
    "    return B\n",
    "\n",
    "def pi_vector(tag_sent_list, tag_set):\n",
    "    first_tag_cnt = defaultdict(lambda: NEAR_ZERO)\n",
    "    for sent in tag_sent_list:\n",
    "        first_tag = sent[0][1]\n",
    "        if first_tag in first_tag_cnt:\n",
    "            first_tag_cnt[first_tag] += 1\n",
    "        else:\n",
    "            first_tag_cnt[first_tag] = 1\n",
    "    sent_cnt = len(tag_sent_list)\n",
    "\n",
    "    vec = defaultdict(lambda: NEAR_ZERO)\n",
    "    for tag in tag_set:\n",
    "        vec[tag] = first_tag_cnt[tag] / sent_cnt\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thuật toán Viterbi trên quan sát, trả về tập quan sát cùng với nhãn dán.\n",
    "def viterbi(obs, tag_set, A, B, pi):\n",
    "    vit_matrix = defaultdict(lambda: NEAR_ZERO)\n",
    "    bck_ptr = defaultdict(lambda: NEAR_ZERO)\n",
    "\n",
    "    # Initial state:\n",
    "    for tag in tag_set:\n",
    "        vit_matrix[(tag, 0)] = pi[tag] * B[(obs[0], tag)]\n",
    "        bck_ptr[(tag, 0)] = (tag, 0)\n",
    "    \n",
    "    for t in range(1, len(obs)):\n",
    "        for tag in tag_set:\n",
    "            x = 0\n",
    "            for tag_before in tag_set:\n",
    "                tmp = vit_matrix[(tag_before, t - 1)] * A[(tag_before, tag)] * B[(obs[t], tag)]\n",
    "                if tmp > x:\n",
    "                    x = tmp\n",
    "                    bck_ptr[(tag, t)] = (tag_before, t - 1)\n",
    "            vit_matrix[(tag, t)] = x\n",
    "    \n",
    "    m = 0\n",
    "    b = None\n",
    "    for tag in tag_set:\n",
    "        if vit_matrix[(tag, len(obs) - 1)] > m:\n",
    "            m = vit_matrix[(tag, len(obs) - 1)]\n",
    "            b = (tag, len(obs) - 1)\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    while b[1] != 0:\n",
    "        result.append((obs[b[1]], b[0]))\n",
    "        b = bck_ptr[b]\n",
    "    result.append((obs[b[1]], b[0]))\n",
    "    return result[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doan van ban ban dau:\n",
      "['every', 'day', 'there', 'is', 'much', 'work', 'to', 'be', 'done', '.']\n",
      "Sau khi dan nhan:\n",
      "[('every', 'DT'), ('day', 'NN'), ('there', 'RB'), ('is', 'VBZ'), ('much', 'RB'), ('work', 'VB'), ('to', 'TO'), ('be', 'VB'), ('done', 'VBN'), ('.', 'SYM')]\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "bi_cnt = bigramCount(list_of_tagged_sents_train)\n",
    "uni_cnt = unigramCount(list_of_tagged_sents_train)\n",
    "wt_cnt = wordtagCount(list_of_tagged_sents_train)\n",
    "\n",
    "A = transition_matrix(tag_set, bi_cnt, uni_cnt)\n",
    "B = emission_matrix(list_of_tagged_sents_train, tag_set, uni_cnt, wt_cnt)\n",
    "pi = pi_vector(list_of_tagged_sents_train, tag_set)\n",
    "\n",
    "obs = [\"every\", \"day\", \"there\", \"is\", \"much\", \"work\", \"to\", \"be\" ,\"done\", \".\"]\n",
    "print(\"Doan van ban ban dau:\")\n",
    "print(obs)\n",
    "print(\"Sau khi dan nhan:\")\n",
    "print(viterbi(obs, tag_set, A, B, pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Đánh giá mô hình\n",
    "Sau khi mô hình đã được xây dựng xong, sẽ thực hiện gán nhãn dựa trên tập `test`, mỗi câu sẽ có tiêu chí đánh giá như sau:\n",
    "$$accuracy =\\frac{correct\\_tag}{total\\_word\\_in\\_sentence}$$\n",
    "Sau đó, sẽ tính toán  độ chính xác trung bình và phương sai, mô hình được gọi là tốt khi có độ chính xác trên `70%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_sentence(sent, tag_set, A, B, pi):\n",
    "    obs = [word[0] for word in sent] # Tách phần chữ\n",
    "    result = viterbi(obs, tag_set, A, B, pi)\n",
    "\n",
    "    correct = 0\n",
    "    assert(len(result) == len(sent))\n",
    "    for i in range(len(result)):\n",
    "        if (sent[i] == result[i]):\n",
    "            correct += 1\n",
    "    return correct / len(sent)\n",
    "\n",
    "acc_list = [calc_accuracy_sentence(sent, tag_set, A, B, pi) * 100 for sent in list_of_tagged_sents_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So luong cau/tu trong tap train: 3801/91266\n",
      "So luong cau/tu trong tap test: 113/2818\n",
      "Do chinh xac cao nhat: 100.0000%\n",
      "Do chinh xac thap nhat: 66.6667%\n",
      "Trung binh: 92.0235%\n",
      "Phuong sai: 38.7941\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(f\"So luong cau/tu trong tap train: {len(list_of_tagged_sents_train)}/{len(sum(list_of_tagged_sents_train, []))}\")\n",
    "print(f\"So luong cau/tu trong tap test: {len(list_of_tagged_sents_test)}/{len(sum(list_of_tagged_sents_test, []))}\")\n",
    "print(f\"Do chinh xac cao nhat: {max(acc_list):.4f}%\")\n",
    "print(f\"Do chinh xac thap nhat: {min(acc_list):.4f}%\")\n",
    "print(f\"Trung binh: {statistics.mean(acc_list):.4f}%\")\n",
    "print(f\"Phuong sai: {statistics.variance(acc_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Nhận xét"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhận xét về kết quả: \n",
    "- Với tập dataset khá nhỏ (~5% so với bản gốc), mô hình có thể đã có thể gán nhãn trên tập test với độ chính xác khá cao (trung bình ~92%)\n",
    "- Tuy nhiên, mô hình vẫn còn chưa ổn định (Phương sai cao: 38.79)\n",
    "- Mô hình sẽ không biết được từ mới (chưa được học) sẽ được gán nhãn gì.\n",
    "Cải tiến:\n",
    "- Tăng tập dataset lên (Dùng 100% dataset), đổi lại thời gian cho việc train sẽ lâu hơn\n",
    "- Sử dụng [Laplace smoothing](https://digitalscholarship.unlv.edu/cgi/viewcontent.cgi?article=2008&context=thesesdissertations) để thêm một số tỉ lệ cho những sự kiện chưa được học ($|V|$ là kích thước tập từ vựng)\n",
    "$$P\\left(w_i|t_{i}\\right) = \\frac{C\\left(t_{i}, w_i\\right) + 1}{C\\left(t_{i}\\right) + |V|}$$\n",
    "- Sử dụng Absolute Discounting để smooth xác suất emission. Gọi $v$ là số lượng từ có xác xuất lớn hơn 0 tại trạng thái $s$, $N$ là kích thước tập từ vựng, $T_s$ là số lượng từ ở trạng thái $s$. Ta có:\n",
    "$$P\\left(w_i|t_{i}\\right)' = \\begin{cases}P\\left(w_i|t_{i}\\right) - p \\quad \\text{Nếu }P\\left(w_i|t_{i}\\right) 0 \\\\ vp/ N-v \\quad \\text{Ngược lại}\\end{cases}$$\n",
    "$$p = \\frac{1}{T_s + v}$$"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
